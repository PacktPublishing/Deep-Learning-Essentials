{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"practical_deep_learning, chapter 3. \n",
    "\n",
    "Examples here are only for the purpose of illustrate the construction of network, \n",
    "using activation functions, and apply for optimization, not for convergence of the \n",
    "network or performance.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define the activation function\n",
    "def sigmoid(x):\n",
    "    return tf.div(tf.constant(1.0),\n",
    "                  tf.add(tf.constant(1.0), tf.exp(tf.neg(x))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Example for Function Approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.5885\n",
      "10.945\n",
      "9.35322\n",
      "11.4281\n",
      "9.54138\n",
      "12.0983\n",
      "11.0501\n",
      "10.1634\n",
      "9.31761\n",
      "11.2674\n"
     ]
    }
   ],
   "source": [
    "# define the function\n",
    "def linear_fun(x):\n",
    "    y = x[:,0] * 2 + x[:,1] * 4 + 1\n",
    "    return y.reshape(y.shape[0],1)\n",
    "    \n",
    "# dimension variables\n",
    "dim_in = 2          \n",
    "dim_middle = 5\n",
    "dim_out = 1\n",
    "\n",
    "# other variables during learning\n",
    "learning_rate = 0.01\n",
    "train_batch_size = 100\n",
    "test_batch_size = 50\n",
    "\n",
    "# declare network variables\n",
    "a_0 = tf.placeholder(tf.float32, [None, dim_in])\n",
    "y = tf.placeholder(tf.float32, [None, dim_out])\n",
    "\n",
    "w_1 = tf.Variable(tf.random_normal([dim_in, dim_middle]))\n",
    "b_1 = tf.Variable(tf.random_normal([dim_middle]))\n",
    "w_2 = tf.Variable(tf.random_normal([dim_middle, dim_out]))\n",
    "b_2 = tf.Variable(tf.random_normal([dim_out]))\n",
    "\n",
    "# build the network structure\n",
    "z_1 = tf.add(tf.matmul(a_0, w_1), b_1)\n",
    "a_1 = sigmoid(z_1)\n",
    "z_2 = tf.add(tf.matmul(a_1, w_2), b_2)\n",
    "a_2 = sigmoid(z_2)\n",
    "\n",
    "# define error, which is the diference between the activation function output and the label\n",
    "error = tf.sub(a_2, y)\n",
    "\n",
    "# define the cost as the square of the errors\n",
    "cost = tf.square(error)\n",
    "res = tf.reduce_mean(tf.cast(cost, tf.float32))\n",
    "\n",
    "# The Gradient Descent Optimizer will do the heavy lifting\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "# Normal TensorFlow - initialize values, create a session and run the model\n",
    "sess = tf.Session()  \n",
    "#sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in range(1000):\n",
    "    x_value = np.random.rand(train_batch_size,2)\n",
    "    y_value = linear_fun(x_value)\n",
    "    sess.run(optimizer, feed_dict={a_0:x_value, y: y_value})\n",
    "    if i % 100 == 0:\n",
    "        test_x = np.random.rand(test_batch_size,2)    \n",
    "        res_val = sess.run(res, feed_dict =\n",
    "                       {a_0: test_x,\n",
    "                        y : linear_fun(test_x)})\n",
    "        print res_val\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example using MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "100.0\n",
      "318.0\n",
      "465.0\n",
      "554.0\n",
      "593.0\n",
      "639.0\n",
      "660.0\n",
      "689.0\n",
      "698.0\n",
      "720.0\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "# dimension variables\n",
    "dim_in = 784\n",
    "dim_middle = 30\n",
    "dim_out = 10\n",
    "\n",
    "# other variables during learning\n",
    "learning_rate = 0.01\n",
    "num_batch = 10\n",
    "\n",
    "# declare variables\n",
    "a_0 = tf.placeholder(tf.float32, [None, dim_in])\n",
    "y = tf.placeholder(tf.float32, [None, dim_out])\n",
    "\n",
    "w_1 = tf.Variable(tf.random_normal([dim_in, dim_middle]))\n",
    "b_1 = tf.Variable(tf.random_normal([dim_middle]))\n",
    "w_2 = tf.Variable(tf.random_normal([dim_middle, dim_out]))\n",
    "b_2 = tf.Variable(tf.random_normal([dim_out]))\n",
    "\n",
    "# build the network structure\n",
    "z_1 = tf.add(tf.matmul(a_0, w_1), b_1)\n",
    "a_1 = sigmoid(z_1)\n",
    "z_2 = tf.add(tf.matmul(a_1, w_2), b_2)\n",
    "a_2 = sigmoid(z_2)\n",
    "\n",
    "acct_mat = tf.equal(tf.argmax(a_2, 1), tf.argmax(y, 1))\n",
    "acct_res = tf.reduce_sum(tf.cast(acct_mat, tf.float32))\n",
    "\n",
    "# define the cost as the square of the errors\n",
    "error = tf.sub(a_2, y)\n",
    "cost = tf.square(error)\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "sess = tf.Session()  # InteractiveSession()\n",
    "#sess.run(tf.global_variables_initializer())\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "for i in xrange(10000):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(num_batch)\n",
    "    sess.run(optimizer, feed_dict = {a_0: batch_xs,\n",
    "                                y : batch_ys})\n",
    "    if i % 1000 == 0:\n",
    "        res = sess.run(acct_res, feed_dict =\n",
    "                       {a_0: mnist.test.images[:1000],\n",
    "                        y : mnist.test.labels[:1000]})\n",
    "        print res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
